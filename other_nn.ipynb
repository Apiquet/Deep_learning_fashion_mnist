{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 conv, 1 pool, BN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "conv1_fmaps = 16\n",
    "conv1_ksize = 4\n",
    "conv1_stride = 1\n",
    "\n",
    "conv2_fmaps = 32\n",
    "conv2_ksize = 4\n",
    "conv2_stride = 2\n",
    "\n",
    "pool1_fmaps = conv1_fmaps\n",
    "\n",
    "conv3_fmaps = 64\n",
    "conv3_ksize = 4\n",
    "conv3_stride = 2\n",
    "\n",
    "conv4_fmaps = 48\n",
    "conv4_ksize = 4\n",
    "conv4_stride = 2\n",
    "\n",
    "pool2_fmaps = conv3_fmaps\n",
    "\n",
    "n_fc1 = 200\n",
    "n_fc2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "in_training_mode = tf.placeholder_with_default(False, shape=[], name='training')\n",
    "#dropout_rate = 0.5\n",
    "\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, height, width], name=\"X\")\n",
    "    X_reshaped = tf.reshape(X, shape=[-1, height, width, channels])\n",
    "    X_normed = tf.layers.batch_normalization(X_reshaped, momentum=0.9, training=in_training_mode) \n",
    "    y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
    "\n",
    "conv1 = tf.layers.conv2d(X_normed, filters=conv1_fmaps, kernel_size=conv1_ksize,\n",
    "                         strides=conv1_stride, padding=\"SAME\",\n",
    "                         activation=None, name=\"conv1\")\n",
    "conv1_BN = tf.layers.batch_normalization(conv1, momentum=0.9, training=in_training_mode)\n",
    "conv1_relu = tf.nn.relu(conv1_BN) \n",
    "\n",
    "conv2 = tf.layers.conv2d(conv1_relu, filters=conv2_fmaps, kernel_size=conv2_ksize,\n",
    "                         strides=conv2_stride, padding=\"SAME\",\n",
    "                         activation=None, name=\"conv2\")\n",
    "\n",
    "conv2_BN = tf.layers.batch_normalization(conv2, momentum=0.9, training=in_training_mode)\n",
    "conv2_relu = tf.nn.relu(conv2_BN) \n",
    "\n",
    "pool1 = tf.nn.max_pool(conv2_relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\", name=\"pool1\")\n",
    "    \n",
    "\n",
    "conv3 = tf.layers.conv2d(pool1, filters=conv3_fmaps, kernel_size=conv3_ksize,\n",
    "                         strides=conv3_stride, padding=\"SAME\",\n",
    "                         activation=None, name=\"conv3\")    \n",
    "conv3_BN = tf.layers.batch_normalization(conv3, momentum=0.9, training=in_training_mode)\n",
    "conv3_relu = tf.nn.relu(conv3_BN) \n",
    "\n",
    "'''with tf.name_scope(\"pool2\"):\n",
    "    pool2 = tf.nn.max_pool(conv3_relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "    pool2_flat = tf.reshape(conv3_relu, shape=[-1, pool2_fmaps * int(pool2.shape[1]) * int(pool2.shape[1])])\n",
    "'''\n",
    "conv3_flat = tf.reshape(conv3_relu, shape=[-1, conv3_fmaps * int(conv3_relu.shape[1]) * int(conv3_relu.shape[1])])\n",
    "                        \n",
    "with tf.name_scope(\"fc1\"):\n",
    "    fc1 = tf.layers.dense(conv3_flat, n_fc1, activation=tf.nn.relu, name=\"fc1\")\n",
    "    #fc1_drop = tf.layers.dropout(fc1, dropout_rate, training=in_training_mode)\n",
    "\n",
    "with tf.name_scope(\"fc2\"):\n",
    "    fc2 = tf.layers.dense(fc1, n_fc2, activation=tf.nn.relu, name=\"fc2\")\n",
    "    #fc2_drop = tf.layers.dropout(fc2, dropout_rate, training=in_training_mode)\n",
    "    \n",
    "with tf.name_scope(\"output\"):\n",
    "    logits = tf.layers.dense(fc2, n_outputs, name=\"output\")\n",
    "    Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "with tf.control_dependencies(update_ops):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    loss_ = tf.summary.scalar('loss', loss)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy_train = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    accuracy_test = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "    accuracy_train_ = tf.summary.scalar('accuracy_train', accuracy_train)\n",
    "    accuracy_test_ = tf.summary.scalar('accuracy_test', accuracy_test)\n",
    "\n",
    "with tf.name_scope(\"init_and_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 conv, 1 pool, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "conv1_fmaps = 16\n",
    "conv1_ksize = 4\n",
    "conv1_stride = 1\n",
    "\n",
    "conv2_fmaps = 32\n",
    "conv2_ksize = 4\n",
    "conv2_stride = 2\n",
    "\n",
    "conv3_fmaps = 64\n",
    "conv3_ksize = 4\n",
    "conv3_stride = 2\n",
    "\n",
    "n_fc1 = 200\n",
    "n_fc2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "in_training_mode = tf.placeholder_with_default(False, shape=[], name='training')\n",
    "dropout_rate = 0.5\n",
    "\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, height, width], name=\"X\")\n",
    "    X_reshaped = tf.reshape(X, shape=[-1, height, width, channels])\n",
    "    y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
    "\n",
    "conv1 = tf.layers.conv2d(X_reshaped, filters=conv1_fmaps, kernel_size=conv1_ksize,\n",
    "                         strides=conv1_stride, padding=\"SAME\",\n",
    "                         activation=tf.nn.relu, name=\"conv1\")\n",
    "\n",
    "conv2 = tf.layers.conv2d(conv1, filters=conv2_fmaps, kernel_size=conv2_ksize,\n",
    "                         strides=conv2_stride, padding=\"SAME\",\n",
    "                         activation=tf.nn.relu, name=\"conv2\")\n",
    "    \n",
    "pool1 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\", name=\"pool1\")\n",
    "\n",
    "conv3 = tf.layers.conv2d(pool1, filters=conv3_fmaps, kernel_size=conv3_ksize,\n",
    "                         strides=conv3_stride, padding=\"SAME\",\n",
    "                         activation=tf.nn.relu, name=\"conv3\") \n",
    "\n",
    "'''with tf.name_scope(\"pool2\"):\n",
    "    pool2 = tf.nn.max_pool(conv3_relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "    pool2_flat = tf.reshape(conv3_relu, shape=[-1, pool2_fmaps * int(pool2.shape[1]) * int(pool2.shape[1])])\n",
    "'''\n",
    "conv3_flat = tf.reshape(conv3, shape=[-1, conv3_fmaps * int(conv3.shape[1]) * int(conv3.shape[1])])\n",
    "\n",
    "with tf.name_scope(\"fc1\"):\n",
    "    fc1 = tf.layers.dense(conv3_flat, n_fc1, activation=tf.nn.relu, name=\"fc1\")\n",
    "    fc1_drop = tf.layers.dropout(fc1, dropout_rate, training=in_training_mode)\n",
    "\n",
    "with tf.name_scope(\"fc2\"):\n",
    "    fc2 = tf.layers.dense(fc1_drop, n_fc2, activation=tf.nn.relu, name=\"fc2\")\n",
    "    fc2_drop = tf.layers.dropout(fc2, dropout_rate, training=in_training_mode)\n",
    "    \n",
    "with tf.name_scope(\"output\"):\n",
    "    logits = tf.layers.dense(fc2_drop, n_outputs, name=\"output\")\n",
    "    Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "with tf.name_scope(\"training\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    loss_ = tf.summary.scalar('loss', loss)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy_train = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    accuracy_test = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "    accuracy_train_ = tf.summary.scalar('accuracy_train', accuracy_train)\n",
    "    accuracy_test_ = tf.summary.scalar('accuracy_test', accuracy_test)\n",
    "\n",
    "with tf.name_scope(\"init_and_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3 conv, 1 pool, No reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "conv1_fmaps = 16\n",
    "conv1_ksize = 4\n",
    "conv1_stride = 1\n",
    "\n",
    "conv2_fmaps = 32\n",
    "conv2_ksize = 4\n",
    "conv2_stride = 2\n",
    "\n",
    "pool1_fmaps = conv1_fmaps\n",
    "\n",
    "conv3_fmaps = 64\n",
    "conv3_ksize = 4\n",
    "conv3_stride = 2\n",
    "\n",
    "pool2_fmaps = conv3_fmaps\n",
    "\n",
    "n_fc1 = 200\n",
    "n_fc2 = 100\n",
    "n_outputs = 10\n",
    "\n",
    "in_training_mode = tf.placeholder_with_default(False, shape=[], name='training')\n",
    "\n",
    "\n",
    "with tf.name_scope(\"inputs\"):\n",
    "    X = tf.placeholder(tf.float32, shape=[None, height, width], name=\"X\")\n",
    "    X_reshaped = tf.reshape(X, shape=[-1, height, width, channels])\n",
    "    y = tf.placeholder(tf.int32, shape=[None], name=\"y\")\n",
    "\n",
    "conv1 = tf.layers.conv2d(X_reshaped, filters=conv1_fmaps, kernel_size=conv1_ksize,\n",
    "                         strides=conv1_stride, padding=\"SAME\",\n",
    "                         activation=tf.nn.relu, name=\"conv1\")\n",
    "\n",
    "conv2 = tf.layers.conv2d(conv1, filters=conv2_fmaps, kernel_size=conv2_ksize,\n",
    "                         strides=conv2_stride, padding=\"SAME\",\n",
    "                         activation=tf.nn.relu, name=\"conv2\")\n",
    "    \n",
    "pool1 = tf.nn.max_pool(conv2, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\", name=\"pool1\")\n",
    "\n",
    "conv3 = tf.layers.conv2d(pool1, filters=conv3_fmaps, kernel_size=conv3_ksize,\n",
    "                         strides=conv3_stride, padding=\"SAME\",\n",
    "                         activation=tf.nn.relu, name=\"conv3\") \n",
    "\n",
    "'''with tf.name_scope(\"pool2\"):\n",
    "    pool2 = tf.nn.max_pool(conv3_relu, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding=\"VALID\")\n",
    "    pool2_flat = tf.reshape(conv3_relu, shape=[-1, pool2_fmaps * int(pool2.shape[1]) * int(pool2.shape[1])])\n",
    "'''\n",
    "conv3_flat = tf.reshape(conv3, shape=[-1, conv3_fmaps * int(conv3.shape[1]) * int(conv3.shape[1])])\n",
    "\n",
    "with tf.name_scope(\"fc1\"):\n",
    "    fc1 = tf.layers.dense(conv3_flat, n_fc1, activation=tf.nn.relu, name=\"fc1\")\n",
    "\n",
    "with tf.name_scope(\"fc2\"):\n",
    "    fc2 = tf.layers.dense(fc1, n_fc2, activation=tf.nn.relu, name=\"fc2\")\n",
    "    \n",
    "with tf.name_scope(\"output\"):\n",
    "    logits = tf.layers.dense(fc2, n_outputs, name=\"output\")\n",
    "    Y_proba = tf.nn.softmax(logits, name=\"Y_proba\")\n",
    "\n",
    "with tf.name_scope(\"training\"):\n",
    "    xentropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=y)\n",
    "    loss = tf.reduce_mean(xentropy)\n",
    "    loss_ = tf.summary.scalar('loss', loss)\n",
    "    optimizer = tf.train.AdamOptimizer()\n",
    "    training_op = optimizer.minimize(loss)\n",
    "\n",
    "with tf.name_scope(\"eval\"):\n",
    "    correct = tf.nn.in_top_k(logits, y, 1)\n",
    "    accuracy_train = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    accuracy_test = tf.reduce_mean(tf.cast(correct, tf.float32))\n",
    "    \n",
    "    accuracy_train_ = tf.summary.scalar('accuracy_train', accuracy_train)\n",
    "    accuracy_test_ = tf.summary.scalar('accuracy_test', accuracy_test)\n",
    "\n",
    "with tf.name_scope(\"init_and_save\"):\n",
    "    init = tf.global_variables_initializer()\n",
    "    saver = tf.train.Saver()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
